{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "# -----------------------------------------------------------------------------\n",
    "# Handler de inferencia para SageMaker (TensorFlow 2.x)\n",
    "# Entradas:\n",
    "#   POST /invocations\n",
    "#   Content-Type: application/json\n",
    "#   {\n",
    "#       \"frames\": [\"<b64_jpeg_1>\", \"<b64_jpeg_2>\", ...]   # cualquier nº de frames\n",
    "#   }\n",
    "# Salidas:\n",
    "#   {\n",
    "#       \"prediction\": 2,\n",
    "#       \"probs\": [0.01, 0.12, 0.80, 0.07]                 # soft-max (orden 0-3)\n",
    "#   }\n",
    "# -----------------------------------------------------------------------------\n",
    "import os, io, json, base64\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# -------------  Hyperparámetros (deben coincidir con entrenamiento) ----------\n",
    "NUM_FRAMES   = 32\n",
    "TARGET_SIZE  = (224, 224)\n",
    "FEAT_DIM     = 1280                     # EfficientNet-B0\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------- Utilidades ------------------------------------\n",
    "def _sample_indices(n_total, n_target):\n",
    "    \"\"\"Devuelve índices equiespaciados para escoger n_target de n_total.\"\"\"\n",
    "    if n_total <= n_target:\n",
    "        return list(range(n_total))\n",
    "    step = n_total / n_target\n",
    "    return [int(i * step) for i in range(n_target)]\n",
    "\n",
    "def _decode_and_resize(b64_str):\n",
    "    \"\"\"Base64 -> PIL -> ndarray RGB normalizado a [0,255], tamaño TARGET_SIZE.\"\"\"\n",
    "    img_bytes = base64.b64decode(b64_str)\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "    img = img.resize(TARGET_SIZE, Image.BILINEAR)\n",
    "    return np.asarray(img, dtype=np.float32)\n",
    "\n",
    "# ----------------------------- SageMaker API ---------------------------------\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Cargamos ambos modelos:\n",
    "      - temporal: tu Bi-LSTM/Transformer entrenado (best_model.h5)\n",
    "      - base: EfficientNet-B0 (ImageNet, sin top)\n",
    "    \"\"\"\n",
    "    temporal = tf.keras.models.load_model(\n",
    "        os.path.join(model_dir, \"best_model.h5\"), compile=False\n",
    "    )\n",
    "\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, weights=\"imagenet\", pooling=\"avg\",\n",
    "        input_shape=TARGET_SIZE + (3,)\n",
    "    )\n",
    "    preprocess = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "    # Guardamos referencias en un dict que SageMaker propagará\n",
    "    return {\"temporal\": temporal, \"base\": base, \"pre\": preprocess}\n",
    "\n",
    "def input_fn(request_body, content_type):\n",
    "    if content_type != \"application/json\":\n",
    "        raise ValueError(f\"Tipo de contenido no soportado: {content_type}\")\n",
    "\n",
    "    body = json.loads(request_body)\n",
    "    if \"frames\" not in body or not isinstance(body[\"frames\"], list):\n",
    "        raise ValueError(\"JSON debe contener la clave 'frames' con una lista.\")\n",
    "\n",
    "    # Lista de tensores imágenes (sin procesar aún)\n",
    "    frames = [_decode_and_resize(b64) for b64 in body[\"frames\"]]\n",
    "    return frames    # lo pasamos tal cual a predict_fn\n",
    "\n",
    "def predict_fn(frames, models):\n",
    "    base        = models[\"base\"]\n",
    "    temporal    = models[\"temporal\"]\n",
    "    preprocess  = models[\"pre\"]\n",
    "\n",
    "    # 1) Sub-muestreo / padding para llegar a NUM_FRAMES\n",
    "    idxs    = _sample_indices(len(frames), NUM_FRAMES)\n",
    "    frames  = [frames[i] for i in idxs]\n",
    "\n",
    "    if len(frames) < NUM_FRAMES:                      # padding si hace falta\n",
    "        pad = [frames[-1]] * (NUM_FRAMES - len(frames))\n",
    "        frames.extend(pad)\n",
    "\n",
    "    # 2) Preprocesamiento EfficientNet\n",
    "    frames_arr = np.stack(frames, axis=0)             # (NUM_FRAMES, H, W, 3)\n",
    "    frames_arr = preprocess(frames_arr)\n",
    "\n",
    "    # 3) Extracción de características en batch\n",
    "    feats = base.predict(frames_arr, verbose=0)       # (NUM_FRAMES, 1280)\n",
    "\n",
    "    # 4) Temporal model (batch=1)\n",
    "    feats = feats.astype(np.float32)[None, ...]       # (1, NUM_FRAMES, 1280)\n",
    "    preds = temporal.predict(feats, verbose=0)[0]     # (4,)\n",
    "\n",
    "    return preds                                      # vector softmax\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    if accept not in (\"application/json\", \"application/json; charset=utf-8\"):\n",
    "        raise ValueError(f\"Tipo de salida no soportado: {accept}\")\n",
    "\n",
    "    pred_class = int(np.argmax(prediction))\n",
    "    resp = json.dumps({\"prediction\": pred_class,\n",
    "                       \"probs\": [float(p) for p in prediction]})\n",
    "    return resp, \"application/json\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
